{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461b6d46",
   "metadata": {},
   "source": [
    "# Advanced Python Programming Problems for Year 8\n",
    "## Data Processing and Analysis Through Real-World Applications\n",
    "\n",
    "### Introduction\n",
    "These problems are designed to introduce advanced programming concepts through practical applications. Each problem builds upon previous knowledge while introducing new concepts. We'll work with real data, create interactive applications, and learn modern programming practices.\n",
    "\n",
    "### Problem 1: Weather Data Analyzer\n",
    "**Concept Focus:** File handling, Data Structures, and Basic Statistics\n",
    "\n",
    "#### Learning Objectives:\n",
    "- Reading data from CSV files\n",
    "- Working with dictionaries and lists\n",
    "- Implementing statistical calculations\n",
    "- Error handling and data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a weather data analyzer that reads temperature data from a CSV file\n",
    "and provides statistical analysis.\n",
    "\n",
    "CSV Format Example:\n",
    "date,temperature,humidity\n",
    "2024-01-01,12.5,65\n",
    "2024-01-02,13.2,70\n",
    "2024-01-03,11.8,68\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class WeatherAnalyzer:\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.temperatures: List[float] = []\n",
    "        self.humidity_data: List[float] = []\n",
    "        self.date_temp_map: Dict[datetime, float] = {}\n",
    "        \n",
    "    def load_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads and validates weather data from CSV file.\n",
    "        Implements error handling for missing or invalid data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(self.filename, 'r') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                for row in reader:\n",
    "                    try:\n",
    "                        date = datetime.strptime(row['date'], '%Y-%m-%d')\n",
    "                        temp = float(row['temperature'])\n",
    "                        humidity = float(row['humidity'])\n",
    "                        \n",
    "                        # Store data in our structures\n",
    "                        self.temperatures.append(temp)\n",
    "                        self.humidity_data.append(humidity)\n",
    "                        self.date_temp_map[date] = temp\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Invalid data in row: {row}. Error: {e}\")\n",
    "                        continue\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Could not find file: {self.filename}\")\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculates basic statistics for temperature data.\n",
    "        Returns dictionary with min, max, average, and range.\n",
    "        \"\"\"\n",
    "        if not self.temperatures:\n",
    "            return {}\n",
    "            \n",
    "        return {\n",
    "            'minimum': min(self.temperatures),\n",
    "            'maximum': max(self.temperatures),\n",
    "            'average': sum(self.temperatures) / len(self.temperatures),\n",
    "            'range': max(self.temperatures) - min(self.temperatures)\n",
    "        }\n",
    "    \n",
    "    def find_temperature_trends(self) -> List[Tuple[datetime, str]]:\n",
    "        \"\"\"\n",
    "        Analyzes temperature trends by comparing consecutive days.\n",
    "        Returns list of dates and trend indicators.\n",
    "        \"\"\"\n",
    "        trends = []\n",
    "        dates = sorted(self.date_temp_map.keys())\n",
    "        \n",
    "        for i in range(1, len(dates)):\n",
    "            prev_temp = self.date_temp_map[dates[i-1]]\n",
    "            curr_temp = self.date_temp_map[dates[i]]\n",
    "            \n",
    "            if curr_temp > prev_temp:\n",
    "                trend = \"increasing\"\n",
    "            elif curr_temp < prev_temp:\n",
    "                trend = \"decreasing\"\n",
    "            else:\n",
    "                trend = \"stable\"\n",
    "                \n",
    "            trends.append((dates[i], trend))\n",
    "            \n",
    "        return trends\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    analyzer = WeatherAnalyzer('weather_data.csv')\n",
    "    try:\n",
    "        analyzer.load_data()\n",
    "        stats = analyzer.get_statistics()\n",
    "        trends = analyzer.find_temperature_trends()\n",
    "        \n",
    "        print(\"Weather Statistics:\")\n",
    "        for key, value in stats.items():\n",
    "            print(f\"{key.capitalize()}: {value:.2f}\")\n",
    "            \n",
    "        print(\"\\nTemperature Trends:\")\n",
    "        for date, trend in trends:\n",
    "            print(f\"{date.strftime('%Y-%m-%d')}: {trend}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3bfd4",
   "metadata": {},
   "source": [
    "#### Advanced Concepts and Best Practices:\n",
    "1. **Type Hints**\n",
    "   - Using Python's type hinting system\n",
    "   - Improves code readability and maintainability\n",
    "   - Enables better IDE support\n",
    "\n",
    "2. **Class Structure**\n",
    "   - Organizing data and methods in a class\n",
    "   - Encapsulation of related functionality\n",
    "   - Clear separation of concerns\n",
    "\n",
    "3. **Error Handling**\n",
    "   - Try-except blocks for file operations\n",
    "   - Validation of input data\n",
    "   - Graceful error reporting\n",
    "\n",
    "4. **Data Structures**\n",
    "   - Using appropriate data structures (lists, dictionaries)\n",
    "   - Efficient data organization\n",
    "   - Easy access patterns\n",
    "\n",
    "### Problem 2: Text Analysis Engine\n",
    "**Concept Focus:** Natural Language Processing Basics\n",
    "\n",
    "This problem introduces basic text analysis concepts including:\n",
    "- Word frequency analysis\n",
    "- Sentence structure analysis\n",
    "- Basic text statistics\n",
    "- Pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "class TextAnalyzer:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        self.words: List[str] = []\n",
    "        self.sentences: List[str] = []\n",
    "        self.word_frequencies: Dict[str, int] = {}\n",
    "        self.prepare_text()\n",
    "        \n",
    "    def prepare_text(self) -> None:\n",
    "        \"\"\"\n",
    "        Preprocesses text by:\n",
    "        1. Splitting into sentences\n",
    "        2. Extracting words\n",
    "        3. Removing punctuation\n",
    "        4. Converting to lowercase\n",
    "        \"\"\"\n",
    "        # Split into sentences (basic implementation)\n",
    "        self.sentences = [s.strip() for s in re.split(r'[.!?]+', self.text) if s.strip()]\n",
    "        \n",
    "        # Extract words and clean them\n",
    "        self.words = [\n",
    "            word.lower() for sentence in self.sentences\n",
    "            for word in re.findall(r'\\w+', sentence)\n",
    "        ]\n",
    "        \n",
    "        # Calculate word frequencies\n",
    "        self.word_frequencies = Counter(self.words)\n",
    "    \n",
    "    def get_word_stats(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculates various text statistics.\n",
    "        \"\"\"\n",
    "        if not self.words:\n",
    "            return {}\n",
    "            \n",
    "        return {\n",
    "            'average_word_length': sum(len(word) for word in self.words) / len(self.words),\n",
    "            'unique_words': len(set(self.words)),\n",
    "            'total_words': len(self.words),\n",
    "            'sentence_count': len(self.sentences)\n",
    "        }\n",
    "    \n",
    "    def find_common_words(self, n: int = 5) -> List[Tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        Returns the n most common words and their frequencies.\n",
    "        \"\"\"\n",
    "        return self.word_frequencies.most_common(n)\n",
    "    \n",
    "    def get_sentence_complexity(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Analyzes sentence complexity based on:\n",
    "        - Words per sentence\n",
    "        - Average word length per sentence\n",
    "        - Unique words per sentence\n",
    "        \"\"\"\n",
    "        if not self.sentences:\n",
    "            return {}\n",
    "            \n",
    "        complexities = []\n",
    "        for sentence in self.sentences:\n",
    "            words = re.findall(r'\\w+', sentence.lower())\n",
    "            if words:\n",
    "                complexity = {\n",
    "                    'word_count': len(words),\n",
    "                    'avg_word_length': sum(len(word) for word in words) / len(words),\n",
    "                    'unique_ratio': len(set(words)) / len(words)\n",
    "                }\n",
    "                complexities.append(complexity)\n",
    "        \n",
    "        # Calculate averages across all sentences\n",
    "        return {\n",
    "            'avg_words_per_sentence': sum(c['word_count'] for c in complexities) / len(complexities),\n",
    "            'avg_complexity_score': sum(c['avg_word_length'] * c['unique_ratio'] \n",
    "                                     for c in complexities) / len(complexities)\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    sample_text = \"\"\"\n",
    "    Python is a versatile programming language. It's used in web development, \n",
    "    data analysis, artificial intelligence, and scientific computing! The syntax \n",
    "    is clear and readable, making it great for beginners.\n",
    "    \"\"\"\n",
    "    \n",
    "    analyzer = TextAnalyzer(sample_text)\n",
    "    \n",
    "    print(\"Text Statistics:\")\n",
    "    stats = analyzer.get_word_stats()\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n",
    "    \n",
    "    print(\"\\nMost Common Words:\")\n",
    "    common_words = analyzer.find_common_words()\n",
    "    for word, count in common_words:\n",
    "        print(f\"{word}: {count}\")\n",
    "    \n",
    "    print(\"\\nSentence Complexity:\")\n",
    "    complexity = analyzer.get_sentence_complexity()\n",
    "    for key, value in complexity.items():\n",
    "        print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aebe460",
   "metadata": {},
   "source": [
    "#### Key Learning Points:\n",
    "1. **Regular Expressions**\n",
    "   - Pattern matching for text analysis\n",
    "   - Text cleaning and preprocessing\n",
    "   - Extracting specific patterns\n",
    "\n",
    "2. **Collections Module**\n",
    "   - Using Counter for frequency analysis\n",
    "   - Efficient data structures for counting\n",
    "   - Built-in helper methods\n",
    "\n",
    "3. **Text Processing Techniques**\n",
    "   - Sentence splitting\n",
    "   - Word tokenization\n",
    "   - Basic text statistics\n",
    "\n",
    "4. **Object-Oriented Design**\n",
    "   - Modular code structure\n",
    "   - Reusable components\n",
    "   - Clear method responsibilities\n",
    "\n",
    "[Continued in next problems...]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
